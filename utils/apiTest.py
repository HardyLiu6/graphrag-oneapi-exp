"""
GraphRAG API æµ‹è¯•è„šæœ¬ (é€‚é… GraphRAG 2.7.0)

è¯¥è„šæœ¬ç”¨äºæµ‹è¯• GraphRAG çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿçš„ä¸åŒæœç´¢æ¨¡å¼ã€‚
æ”¯æŒå…¨å±€æœç´¢ã€æœ¬åœ°æœç´¢å’Œç»¼åˆæœç´¢ä¸‰ç§æ¨¡å¼ã€‚

æ—¥æœŸ: 2026-01-28
ä½œè€…: LiuJunDa
"""
import os
os.environ['no_proxy'] = 'localhost,127.0.0.1'

import requests
import json

BASE_URL = "http://localhost:8012"
CHAT_URL = f"{BASE_URL}/v1/chat/completions"
HEALTH_URL = f"{BASE_URL}/health"
MODELS_URL = f"{BASE_URL}/v1/models"

headers = {"Content-Type": "application/json"}


def check_health():
    """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
    try:
        response = requests.get(HEALTH_URL, timeout=5)
        if response.status_code == 200:
            data = response.json()
            print("âœ… æœåŠ¡çŠ¶æ€:")
            print(f"   - ç‰ˆæœ¬: {data.get('version')}")
            print(f"   - GraphRAG: {data.get('graphrag_version')}")
            print(f"   - æœ¬åœ°æœç´¢: {'å°±ç»ª' if data.get('local_search_ready') else 'æœªå°±ç»ª'}")
            print(f"   - å…¨å±€æœç´¢: {'å°±ç»ª' if data.get('global_search_ready') else 'æœªå°±ç»ª'}")
            return True
        else:
            print(f"âŒ æœåŠ¡å¼‚å¸¸: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡ï¼Œè¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨")
        return False


def list_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    response = requests.get(MODELS_URL)
    if response.status_code == 200:
        models = response.json()['data']
        print("\nğŸ“‹ å¯ç”¨æ¨¡å‹:")
        for m in models:
            print(f"   - {m['id']}")


def test_search(model: str, query: str, stream: bool = False):
    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
    data = {
        "model": model,
        "messages": [{"role": "user", "content": query}],
        "temperature": 0.7,
        "stream": stream,
    }
    
    print(f"\nğŸ” æµ‹è¯•æ¨¡å‹: {model}")
    print(f"   é—®é¢˜: {query[:50]}...")
    
    if stream:
        # æµå¼è¾“å‡º
        with requests.post(CHAT_URL, stream=True, headers=headers, data=json.dumps(data)) as response:
            print("   å›ç­”: ", end="")
            for line in response.iter_lines():
                if line:
                    line_str = line.decode('utf-8')
                    if line_str.startswith("data: ") and line_str != "data: [DONE]":
                        try:
                            json_data = json.loads(line_str[6:])
                            content = json_data.get('choices', [{}])[0].get('delta', {}).get('content', '')
                            print(content, end="", flush=True)
                        except json.JSONDecodeError:
                            pass
            print()  # æ¢è¡Œ
    else:
        # éæµå¼è¾“å‡º
        response = requests.post(CHAT_URL, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            content = response.json()['choices'][0]['message']['content']
            print(f"   å›ç­”:\n{content[:500]}...")
        else:
            print(f"   âŒ é”™è¯¯: {response.status_code} - {response.text}")


if __name__ == "__main__":
    print("=" * 60)
    print("GraphRAG API æµ‹è¯• (v2.7.0)")
    print("=" * 60)
    
    # 1. å¥åº·æ£€æŸ¥
    if not check_health():
        exit(1)
    
    # 2. åˆ—å‡ºæ¨¡å‹
    list_models()
    
    # 3. æµ‹è¯•æŸ¥è¯¢
    # test_query = "éŸ©ç«‹çš„åå­—æ˜¯è°ç»™èµ·çš„ï¼Ÿ"
    test_query = "è¯·ä»‹ç»ä¸€ä¸‹å‡¡äººä¿®ä»™ä¼ å‰å››ç« çš„ä¸»è¦å†…å®¹ã€‚"
    
    # æµ‹è¯•å…¨å±€æœç´¢
    test_search("graphrag-global-search:latest", test_query)
    
    # æµ‹è¯•æœ¬åœ°æœç´¢
    # test_search("graphrag-local-search:latest", test_query)
    
    # æµ‹è¯•ç»¼åˆæœç´¢
    # test_search("full-model:latest", test_query)
    
    # æµ‹è¯•æµå¼è¾“å‡º
    # test_search("graphrag-local-search:latest", test_query, stream=True)